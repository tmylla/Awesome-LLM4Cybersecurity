# LLM4Cybersecurity
> An overview of LLMs for cybersecurity

## Overview

- [ ] overview map: figure 
- [ ] category outline: figure
- [ ] literature review: table


#### Threat Intelligence

1. LOCALINTEL: Generating Organizational Threat Intelligence from Global and Local Cyber Knowledge [[<u>paper</u>]](https://arxiv.org/abs/2401.10036)

2. AGIR: Automating Cyber Threat Intelligence Reporting with Natural Language Generation [[<u>paper</u>]](https://ieeexplore.ieee.org/abstract/document/10386116)

3. On the Uses of Large Language Models to Interpret Ambiguous Cyberattack Descriptions [[<u>paper</u>]](https://arxiv.org/abs/2306.14062)

4. Advancing TTP Analysis: Harnessing the Power of Encoder-Only and Decoder-Only Language Models with Retrieval Augmented Generation [[<u>paper</u>]](https://arxiv.org/abs/2401.00280)

5. An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures [[<u>paper</u>]](https://arxiv.org/abs/2308.04898)

6. ChatGPT, Llama, can you write my report? An experiment on assisted digital forensics reports written using (Local) Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2312.14607)

7. Time for aCTIon: Automated Analysis of Cyber Threat Intelligence in the Wild [[<u>paper</u>]](https://arxiv.org/abs/2307.10214)

8. Cupid: Leveraging ChatGPT for More Accurate Duplicate Bug Report Detection [[<u>paper</u>]](https://arxiv.org/abs/2308.10022)

9. HW-V2W-Map: Hardware Vulnerability to Weakness Mapping Framework for Root Cause Analysis with GPT-assisted Mitigation Suggestion [[<u>paper</u>]](https://arxiv.org/abs/2312.13530)

10. Cyber Sentinel: Exploring Conversational Agents in Streamlining Security Tasks with GPT-4 [[<u>paper</u>]](https://arxiv.org/abs/2309.16422)

11. Evaluation of LLM Chatbots for OSINT-based Cyber Threat Awareness [[<u>paper</u>]](https://arxiv.org/abs/2401.15127)

12. Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2403.00878)

#### FUZZ

1. Augmenting Greybox Fuzzing with Generative AI [[<u>paper</u>]](https://arxiv.org/abs/2306.06782)

2. How well does LLM generate security tests? [[<u>paper</u>]](https://arxiv.org/abs/2310.00710)

3. Fuzz4All: Universal Fuzzing with Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2308.04748)

4. CODAMOSA: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models [[<u>paper</u>]](https://ieeexplore.ieee.org/document/10172800/)

5. Understanding Large Language Model Based Fuzz Driver Generation [[<u>paper</u>]](https://arxiv.org/abs/2307.12469)

6. Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2212.14834)

7. Large Language Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT [[<u>paper</u>]](https://arxiv.org/abs/2304.02014)

8. Large language model guided protocol fuzzing [[<u>paper</u>]](https://www.ndss-symposium.org/wp-content/uploads/2024-556-paper.pdf?ref=blog.exploits.club)

9. Fuzzing BusyBox: Leveraging LLM and Crash Reuse for Embedded Bug Unearthing [[<u>paper</u>]](https://arxiv.org/abs/2403.03897)

#### Vulnerabilities Detection

1. Evaluation of ChatGPT Model for Vulnerability Detection [[<u>paper</u>]](https://arxiv.org/abs/2304.07232)

2. Detecting software vulnerabilities using Language Models [[<u>paper</u>]](https://arxiv.org/abs/2302.11773)

3. Software Vulnerability Detection using Large Language Models [[<u>paper</u>]](https://ieeexplore.ieee.org/document/10301302/)

4. Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities [[<u>paper</u>]](https://arxiv.org/abs/2311.16169)

5. Software Vulnerability and Functionality Assessment using LLMs [[<u>paper</u>]](https://arxiv.org/abs/2403.08429)

6. Finetuning Large Language Models for Vulnerability Detection [[<u>paper</u>]](https://arxiv.org/abs/2401.17010)

7. The Hitchhiker's Guide to Program Analysis: A Journey with Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2308.00245)

8. DefectHunter: A Novel LLM-Driven Boosted-Conformer-based Code Vulnerability Detection Mechanism [[<u>paper</u>]](https://arxiv.org/abs/2309.15324)

9. Prompt-Enhanced Software Vulnerability Detection Using ChatGPT [[<u>paper</u>]](https://arxiv.org/abs/2308.12697)

10. Using ChatGPT as a Static Application Security Testing Tool [[<u>paper</u>]](https://arxiv.org/abs/2308.14434)

11. LLbezpeky: Leveraging Large Language Models for Vulnerability Detection [[<u>paper</u>]](https://arxiv.org/abs/2401.01269)

12. Large Language Model-Powered Smart Contract Vulnerability Detection: New Perspectives [[<u>paper</u>]](https://arxiv.org/abs/2310.01152)

13. Software Vulnerability Detection with GPT and In-Context Learning [[<u>paper</u>]](https://ieeexplore.ieee.org/abstract/document/10381286)

14. GPTScan: Detecting Logic Vulnerabilities in Smart Contracts by Combining GPT with Program Analysis [[<u>paper</u>]](https://arxiv.org/abs/2308.03314)

15. VulLibGen: Identifying Vulnerable Third-Party Libraries via Generative Pre-Trained Model [[<u>paper</u>]](https://arxiv.org/abs/2308.04662)

16. LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning [[<u>paper</u>]](https://arxiv.org/abs/2401.16185)

17. Large Language Models for Test-Free Fault Localization [[<u>paper</u>]](https://arxiv.org/abs/2310.01726)
 
18. Multi-role Consensus through LLMs Discussions for Vulnerability Detection [[<u>paper</u>]](https://arxiv.org/abs/2403.14274)

19. How ChatGPT is Solving Vulnerability Management Problem [[<u>paper</u>]](https://arxiv.org/abs/2311.06530)

20. DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection [[<u>paper</u>]](https://arxiv.org/abs/2304.00409)

21. The FormAI Dataset: Generative AI in Software Security through the Lens of Formal Verification [[<u>paper</u>]](https://arxiv.org/abs/2307.02192)

22. How Far Have We Gone in Vulnerability Detection Using Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2311.12420)

#### Insecure code Generation

1. Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants [[<u>paper</u>]](https://arxiv.org/abs/2208.09727)

2. Bugs in Large Language Models Generated Code [[<u>paper</u>]](https://arxiv.org/abs/2403.08937)

3. Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions [[<u>paper</u>]](https://arxiv.org/abs/2108.09293)

4. The Effectiveness of Large Language Models (ChatGPT and CodeBERT) for Security-Oriented Code Analysis [[<u>paper</u>]](https://arxiv.org/abs/2307.12488)

5. No Need to Lift a Finger Anymore? Assessing the Quality of Code Generation by ChatGPT [[<u>paper</u>]](https://arxiv.org/abs/2308.04838)

6. Generate and Pray: Using SALLMS to Evaluate the Security of LLM Generated Code [[<u>paper</u>]](https://arxiv.org/abs/2311.00889)

7. Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation [[<u>paper</u>]](https://arxiv.org/abs/2305.01210)

8. Can Large Language Models Identify And Reason About Security Vulnerabilities? Not Yet [[<u>paper</u>]](https://arxiv.org/abs/2312.12575)

9. A Comparative Study of Code Generation using ChatGPT 3.5 across 10 Programming Languages [[<u>paper</u>]](https://arxiv.org/abs/2308.04477)

10. How Secure is Code Generated by ChatGPT? [[<u>paper</u>]](How Secure is Code Generated by ChatGPT?)

11. Large Language Models for Code: Security Hardening and Adversarial Testing [[<u>paper</u>]](https://arxiv.org/abs/2302.05319)

12. Pop Quiz! Can a Large Language Model Help With Reverse Engineering? [[<u>paper</u>]](https://arxiv.org/abs/2202.01142)

13. LLM4Decompile: Decompiling Binary Code with Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2403.05286)

14. Large Language Models for Code Analysis: Do LLMs Really Do Their Job? [[<u>paper</u>]](https://arxiv.org/abs/2310.12357)

15. Understanding Programs by Exploiting (Fuzzing) Test Cases [[<u>paper</u>]](https://arxiv.org/abs/2305.13592)

16. Evaluating and Explaining Large Language Models for Code Using Syntactic Structures [[<u>paper</u>]](https://arxiv.org/abs/2308.03873)

17. Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4 [[<u>paper</u>]](https://arxiv.org/abs/2312.08317)

18. Using ChatGPT to Analyze Ransomware Messages and to Predict Ransomware Threats [[<u>paper</u>]](https://www.researchgate.net/publication/375827732_Using_ChatGPT_to_Analyze_Ransomware_Messages_and_to_Predict_Ransomware_Threats)

19. Shifting the Lens: Detecting Malware in npm Ecosystem with Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2403.12196)

20. DebugBench: Evaluating Debugging Capability of Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2401.04621)

21. Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI Testing via Functionality-aware Decisions [[<u>paper</u>]](https://arxiv.org/abs/2310.15780)

22. FLAG: Finding Line Anomalies (in code) with Generative AI [[<u>paper</u>]](https://arxiv.org/abs/2306.12643)

#### Program Repair 

1. Automatic Program Repair with OpenAI's Codex: Evaluating QuixBugs [[<u>paper</u>]](https://arxiv.org/abs/2111.03922)

2. An Analysis of the Automatic Bug Fixing Performance of ChatGPT [[<u>paper</u>]](https://arxiv.org/abs/2301.08653)

3. AI-powered patching: the future of automated vulnerability fixes [[<u>paper</u>]](https://research.google/pubs/ai-powered-patching-the-future-of-automated-vulnerability-fixes/)

4. Practical Program Repair in the Era of Large Pre-trained Language Models [[<u>paper</u>]](https://arxiv.org/abs/2210.14179)

5. Security Code Review by LLMs: A Deep Dive into Responses  [[<u>paper</u>]](https://arxiv.org/abs/2401.16310)

6. Examining Zero-Shot Vulnerability Repair with Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2112.02125)

7. How Effective Are Neural Networks for Fixing Security Vulnerabilities [[<u>paper</u>]](https://arxiv.org/abs/2305.18607)

8. Can LLMs Patch Security Issues? [[<u>paper</u>]](https://arxiv.org/abs/2312.00024)

9. InferFix: End-to-End Program Repair with LLMs [[<u>paper</u>]](https://arxiv.org/abs/2303.07263)

10. ZeroLeak: Using LLMs for Scalable and Cost Effective Side-Channel Patching [[<u>paper</u>]](https://arxiv.org/abs/2308.13062)

11. DIVAS: An LLM-based End-to-End Framework for SoC Security Analysis and Policy-based Protection [[<u>paper</u>]](https://arxiv.org/abs/2308.06932)

12. Fixing Hardware Security Bugs with Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2302.01215)

13. A Study of Vulnerability Repair in JavaScript Programs with Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2403.13193)

14. Enhanced Automated Code Vulnerability Repair using Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2401.03741)

15. Teaching Large Language Models to Self-Debug [[<u>paper</u>]](https://arxiv.org/abs/2304.05128)

16. Better Patching Using LLM Prompting, via Self-Consistency [[<u>paper</u>]](https://arxiv.org/abs/2306.00108)

17. Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair [[<u>paper</u>]](https://arxiv.org/abs/2309.00608)
 
18. LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward [[<u>paper</u>]](https://arxiv.org/abs/2401.03374)

19. ContrastRepair: Enhancing Conversation-Based Automated Program Repair via Contrastive Test Case Pairs [[<u>paper</u>]](https://arxiv.org/abs/2403.01971)

20. When Large Language Models Confront Repository-Level Automatic Program Repair: How Well They Done? [[<u>paper</u>]](https://arxiv.org/abs/2403.00448)

#### Anomaly Detection

1. Benchmarking Large Language Models for Log Analysis, Security, and Interpretation [[<u>paper</u>]](https://arxiv.org/abs/2311.14519)

2. Log-based Anomaly Detection based on EVT Theory with feedback [[<u>paper</u>]](https://arxiv.org/abs/2306.05032)

3. LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection [[<u>paper</u>]](https://arxiv.org/abs/2309.01189)

4. LogGPT: Log Anomaly Detection via GPT [[<u>paper</u>]](https://arxiv.org/abs/2309.14482)

5. Interpretable Online Log Analysis Using Large Language Models with Prompt Strategies [[<u>paper</u>]](https://arxiv.org/abs/2308.07610)

6. Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging [[<u>paper</u>]](https://arxiv.org/abs/2402.18205)

7. Web Content Filtering through knowledge distillation of Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2305.05027)

8. Application of Large Language Models to DDoS Attack Detection [[<u>paper</u>]](https://link.springer.com/chapter/10.1007/978-3-031-51630-6_6)

9. An Improved Transformer-based Model for Detecting Phishing, Spam, and Ham: A Large Language Model Approach [[<u>paper</u>]](https://arxiv.org/abs/2311.04913)

10. Evaluating the Performance of ChatGPT for Spam Email Detection [[<u>paper</u>]](https://arxiv.org/abs/2402.15537)
 
11. Prompted Contextual Vectors for Spear-Phishing Detection [[<u>paper</u>]](https://arxiv.org/abs/2402.08309)

12. Devising and Detecting Phishing: Large Language Models vs. Smaller Human Models [[<u>paper</u>]](https://arxiv.org/abs/2308.12287)

13. Explaining Tree Model Decisions in Natural Language for Network Intrusion Detection [[<u>paper</u>]](https://arxiv.org/abs/2310.19658)

14. Revolutionizing Cyber Threat Detection with Large Language Models: A privacy-preserving BERT-based Lightweight Model for IoT/IIoT Devices [[<u>paper</u>]](https://ieeexplore.ieee.org/document/10423646)

15. HuntGPT: Integrating Machine Learning-Based Anomaly Detection and Explainable AI with Large Language Models (LLMs) [[<u>paper</u>]](https://arxiv.org/abs/2309.16021)

16. ChatGPT for digital forensic investigation: The good, the bad, and the unknown [[<u>paper</u>]](https://arxiv.org/abs/2307.10195)

#### LLM Assisted Attack

1. Identifying and mitigating the security risks of generative ai [[<u>paper</u>]](https://arxiv.org/abs/2308.14840)

2. Impact of Big Data Analytics and ChatGPT on Cybersecurity [[<u>paper</u>]](https://ieeexplore.ieee.org/document/10127411)

3. From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy [[<u>paper</u>]](https://arxiv.org/abs/2307.00691)
 
4. LLMs Killed the Script Kiddie: How Agents Supported by Large Language Models Change the Landscape of Network Threat Testing [[<u>paper</u>]](https://arxiv.org/abs/2310.06936)

5. Malla: Demystifying Real-world Large Language Model Integrated Malicious Services [[<u>paper</u>]](https://arxiv.org/abs/2401.03315)

6. Evaluating LLMs for Privilege-Escalation Scenarios [[<u>paper</u>]](https://arxiv.org/abs/2310.11409)

7. Using Large Language Models for Cybersecurity Capture-The-Flag Challenges and Certification Questions [[<u>paper</u>]](https://arxiv.org/abs/2308.10443)

8. Exploring the Dark Side of AI: Advanced Phishing Attack Design and Deployment Using ChatGPT [[<u>paper</u>]](https://arxiv.org/abs/2309.10463)
 
9. From Chatbots to PhishBots? - Preventing Phishing scams created using ChatGPT, Google Bard and Claude [[<u>paper</u>]](https://arxiv.org/abs/2310.19181)

10. From Text to MITRE Techniques: Exploring the Malicious Use of Large Language Models for Generating Cyber Attack Payloads [[<u>paper</u>]]()

11. PentestGPT: An LLM-empowered Automatic Penetration Testing Tool [[<u>paper</u>]](https://arxiv.org/abs/2308.06782)

12. AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks [[<u>paper</u>]](https://arxiv.org/abs/2403.01038)

13. RatGPT: Turning online LLMs into Proxies for Malware Attacks [[<u>paper</u>]](https://arxiv.org/abs/2308.09183)

14. Getting pwn’d by AI: Penetration Testing with Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2308.00121)

#### Others

1. An LLM-based Framework for Fingerprinting Internet-connected Devices [[<u>paper</u>]](https://dl.acm.org/doi/pdf/10.1145/3618257.3624845)
   
2. Anatomy of an AI-powered malicious social botnet [[<u>paper</u>]](https://arxiv.org/abs/2307.16336)

3. Just-in-Time Security Patch Detection -- LLM At the Rescue for Data Augmentation [[<u>paper</u>]](https://arxiv.org/abs/2312.01241)

4. LLM for SoC Security: A Paradigm Shift [[<u>paper</u>]](https://arxiv.org/abs/2310.06046)

5. Harnessing the Power of LLM to Support Binary Taint Analysis [[<u>paper</u>]](https://arxiv.org/abs/2310.08275)

6. Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations [[<u>paper</u>]](https://arxiv.org/abs/2312.06674)

7. LLM in the Shell: Generative Honeypots [[<u>paper</u>]](https://arxiv.org/abs/2309.00155)

8. Employing LLMs for Incident Response Planning and Review [[<u>paper</u>]](https://arxiv.org/abs/2403.01271)

9. Enhancing Network Management Using Code Generated by Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2308.06261)

10. Prompting Is All You Need: Automated Android Bug Replay with Large Language Models [[<u>paper</u>]](https://arxiv.org/abs/2306.01987)

11. Is Stack Overflow Obsolete? An Empirical Study of the Characteristics of ChatGPT Answers to Stack Overflow Questions [[<u>paper</u>]](https://arxiv.org/abs/2308.02312)
